{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Original work: https://www.kaggle.com/debarshichanda/pytorch-w-b-jigsaw-starter\n#### This notebook applies the same strategy by augmenting the data from other Jigsaw competitions (toxic classification , Ruddit Data, Jigsaw Unintended Bias data) by creating less toxic - more toxic pairs and training ROBERTA on the augmented data\n\n### LB score: 0.834\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-20T14:43:56.325559Z","iopub.execute_input":"2022-01-20T14:43:56.32588Z","iopub.status.idle":"2022-01-20T14:43:56.372542Z","shell.execute_reply.started":"2022-01-20T14:43:56.325848Z","shell.execute_reply":"2022-01-20T14:43:56.371546Z"}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport time\nimport random\nimport string\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\n# Utils\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel, AdamW\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\ny_ = Fore.YELLOW\nsr_ = Style.RESET_ALL\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:43:56.375228Z","iopub.execute_input":"2022-01-20T14:43:56.375612Z","iopub.status.idle":"2022-01-20T14:44:04.408896Z","shell.execute_reply.started":"2022-01-20T14:43:56.375565Z","shell.execute_reply":"2022-01-20T14:44:04.408124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"w_b\")\n    wandb.login(key=api_key)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:04.410148Z","iopub.execute_input":"2022-01-20T14:44:04.411151Z","iopub.status.idle":"2022-01-20T14:44:06.791673Z","shell.execute_reply.started":"2022-01-20T14:44:04.411109Z","shell.execute_reply":"2022-01-20T14:44:06.790788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n\nHASH_NAME = id_generator(size=12)\nprint(HASH_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:06.793112Z","iopub.execute_input":"2022-01-20T14:44:06.793813Z","iopub.status.idle":"2022-01-20T14:44:06.800953Z","shell.execute_reply.started":"2022-01-20T14:44:06.793774Z","shell.execute_reply":"2022-01-20T14:44:06.800014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\"seed\":42,\n         \"num_epochs\":3,\n         \"train_batch_size\": 16,\n          \"val_batch_size\":32,\n          \"model_name\":\"roberta-base\",\n         \"learning_rate\": 1e-4,\n          \"scheduler\": None,\n          \"min_lr\": 1e-6,\n          \"n_fold\":3,\n          \"weight_decay\":1e-6,\n          \"T_max\": 500,\n          \"num_classes\":1,\n          \"margin\": 0.5,\n          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n          \"hash_name\": HASH_NAME,\n          \"max_length\":256}\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG[\"model_name\"])\nCONFIG[\"group\"] = 'f{HASH_NAME}-Baseline'","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:06.804028Z","iopub.execute_input":"2022-01-20T14:44:06.804663Z","iopub.status.idle":"2022-01-20T14:44:10.428185Z","shell.execute_reply.started":"2022-01-20T14:44:06.804607Z","shell.execute_reply":"2022-01-20T14:44:10.427492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:10.429462Z","iopub.execute_input":"2022-01-20T14:44:10.430193Z","iopub.status.idle":"2022-01-20T14:44:10.439424Z","shell.execute_reply.started":"2022-01-20T14:44:10.430159Z","shell.execute_reply":"2022-01-20T14:44:10.438673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:10.440849Z","iopub.execute_input":"2022-01-20T14:44:10.441995Z","iopub.status.idle":"2022-01-20T14:44:11.049451Z","shell.execute_reply.started":"2022-01-20T14:44:10.441869Z","shell.execute_reply":"2022-01-20T14:44:11.048568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df))\nlen(np.unique(np.concatenate([df[\"less_toxic\"], df[\"more_toxic\"]])))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:11.050731Z","iopub.execute_input":"2022-01-20T14:44:11.051649Z","iopub.status.idle":"2022-01-20T14:44:11.163011Z","shell.execute_reply.started":"2022-01-20T14:44:11.051606Z","shell.execute_reply":"2022-01-20T14:44:11.162243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Ruddit data","metadata":{"execution":{"iopub.status.busy":"2021-12-25T15:16:17.334362Z","iopub.execute_input":"2021-12-25T15:16:17.334896Z","iopub.status.idle":"2021-12-25T15:16:17.338867Z","shell.execute_reply.started":"2021-12-25T15:16:17.334849Z","shell.execute_reply":"2021-12-25T15:16:17.338248Z"}}},{"cell_type":"code","source":"df_ruddit = pd.read_csv(\"/kaggle/input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\ndf_ruddit = df_ruddit[df_ruddit[\"txt\"]!=\"[deleted]\"]\nlen(df_ruddit)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:11.164021Z","iopub.execute_input":"2022-01-20T14:44:11.164804Z","iopub.status.idle":"2022-01-20T14:44:11.23572Z","shell.execute_reply.started":"2022-01-20T14:44:11.164767Z","shell.execute_reply":"2022-01-20T14:44:11.234808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ruddit[\"offensiveness_score\"] = (df_ruddit[\"offensiveness_score\"] - df_ruddit[\"offensiveness_score\"].min() )/ (df_ruddit[\"offensiveness_score\"].max() - df_ruddit[\"offensiveness_score\"].min() )","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:11.237251Z","iopub.execute_input":"2022-01-20T14:44:11.237753Z","iopub.status.idle":"2022-01-20T14:44:11.245408Z","shell.execute_reply.started":"2022-01-20T14:44:11.23771Z","shell.execute_reply":"2022-01-20T14:44:11.244418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncomment_pairs = []\nfor index, row in df_ruddit.iterrows():\n    low_toxic_df = df_ruddit[df_ruddit[\"offensiveness_score\"]<=(row[\"offensiveness_score\"] - 0.3)]\n#     print(low_toxic_df)\n    if len(low_toxic_df)>=4:\n        low_toxic = low_toxic_df.sample(n=4, random_state = index+1).reset_index(drop=True)\n        comment_pairs.append((low_toxic[\"txt\"][0], row[\"txt\"]))\n        comment_pairs.append((low_toxic[\"txt\"][1], row[\"txt\"]))\n    more_toxic_df= df_ruddit[df_ruddit[\"offensiveness_score\"]>=(row[\"offensiveness_score\"] + 0.3)]\n    if len(more_toxic_df)>=4:\n        more_toxic =  more_toxic_df.sample(n=4, random_state = index+2).reset_index(drop=True)\n        comment_pairs.append(( row[\"txt\"],more_toxic[\"txt\"][0]))\n        comment_pairs.append(( row[\"txt\"],more_toxic[\"txt\"][1]))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:11.247092Z","iopub.execute_input":"2022-01-20T14:44:11.248105Z","iopub.status.idle":"2022-01-20T14:44:24.674727Z","shell.execute_reply.started":"2022-01-20T14:44:11.248057Z","shell.execute_reply":"2022-01-20T14:44:24.673697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ruddit_final = pd.DataFrame(comment_pairs, columns= [\"less_toxic\",\"more_toxic\"])\ndf_ruddit_final","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:24.676188Z","iopub.execute_input":"2022-01-20T14:44:24.67651Z","iopub.status.idle":"2022-01-20T14:44:24.696161Z","shell.execute_reply.started":"2022-01-20T14:44:24.676466Z","shell.execute_reply":"2022-01-20T14:44:24.695364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare toxic classification data","metadata":{}},{"cell_type":"code","source":"\n\ndf_classification = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ndf_classification.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:24.698702Z","iopub.execute_input":"2022-01-20T14:44:24.698954Z","iopub.status.idle":"2022-01-20T14:44:26.716612Z","shell.execute_reply.started":"2022-01-20T14:44:24.698923Z","shell.execute_reply":"2022-01-20T14:44:26.715701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Overlapping comments\n\n### Total unique comments in severity data\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\nprint(df_val.shape)\ntot_unique_comments = np.unique(np.concatenate([df_val[\"less_toxic\"], df_val[\"more_toxic\"]]))\nprint(\"total unique: \", len(tot_unique_comments))\n\n\n# Find cases already present in toxic data\n\ndf_val_1 = pd.merge(df_val, df_classification.loc[:,['comment_text']], \n                  left_on = 'less_toxic', \n                  right_on = 'comment_text', how='inner')\n# print(df_val_1.shape)\n\ndf_val_2 = pd.merge(df_val, df_classification.loc[:,['comment_text']], \n                  left_on = 'more_toxic', \n                  right_on = 'comment_text', how='inner')\n# print(df_val_2.shape)\n\ntot_unique_common = np.unique(np.concatenate([df_val_1[\"comment_text\"], df_val_2[\"comment_text\"]]))\nprint(\"total common: \", len(tot_unique_common))\n\n# Removing those cases\ndf_classification_u = df_classification[~df_classification[\"comment_text\"].isin(tot_unique_common)]\nprint(\"total uncommon :\", len(df_classification_u) )","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:26.718248Z","iopub.execute_input":"2022-01-20T14:44:26.718558Z","iopub.status.idle":"2022-01-20T14:44:27.412022Z","shell.execute_reply.started":"2022-01-20T14:44:26.718526Z","shell.execute_reply":"2022-01-20T14:44:27.411264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_classification_u[\"neutral\"] = 1 - df_classification_u[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].max(axis=1)\nmore_toxic = df_classification_u[df_classification_u[[\"severe_toxic\",\"threat\", \"toxic\"]].max(axis=1)>=2][\"comment_text\"]\nless_toxic = df_classification_u[df_classification_u[\"neutral\"]==1].sample(n = 10*len(more_toxic), random_state = CONFIG[\"seed\"])\nlen(less_toxic), len(more_toxic)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:27.413461Z","iopub.execute_input":"2022-01-20T14:44:27.413672Z","iopub.status.idle":"2022-01-20T14:44:27.461748Z","shell.execute_reply.started":"2022-01-20T14:44:27.413645Z","shell.execute_reply":"2022-01-20T14:44:27.460951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"more_toxic = more_toxic.repeat(5)\n\nfor l_t, m_t in zip(less_toxic, more_toxic):\n    comment_pairs.append((l_t,m_t))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:27.462689Z","iopub.execute_input":"2022-01-20T14:44:27.462935Z","iopub.status.idle":"2022-01-20T14:44:27.468558Z","shell.execute_reply.started":"2022-01-20T14:44:27.462906Z","shell.execute_reply":"2022-01-20T14:44:27.467666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Jigsaw unintended Bias data","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:12:29.153073Z","iopub.execute_input":"2021-12-26T05:12:29.153575Z","iopub.status.idle":"2021-12-26T05:12:29.159076Z","shell.execute_reply.started":"2021-12-26T05:12:29.153537Z","shell.execute_reply":"2021-12-26T05:12:29.158416Z"}}},{"cell_type":"code","source":"pd.set_option(\"display.max_columns\",500)\ndf_multi = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")\ndf_multi.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:27.470444Z","iopub.execute_input":"2022-01-20T14:44:27.470752Z","iopub.status.idle":"2022-01-20T14:44:53.973608Z","shell.execute_reply.started":"2022-01-20T14:44:27.47071Z","shell.execute_reply":"2022-01-20T14:44:53.972803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_multi[\"identity_associated\"] = df_multi.iloc[:,8:-13].sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T14:44:53.974757Z","iopub.execute_input":"2022-01-20T14:44:53.97498Z","iopub.status.idle":"2022-01-20T14:44:54.625189Z","shell.execute_reply.started":"2022-01-20T14:44:53.974952Z","shell.execute_reply":"2022-01-20T14:44:54.624239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_multi[\"neutral\"] = df_multi[[\"toxic\",\"severe_toxicity\",\"obscene\",\"threat\",\"insult\",\"identity_attack\"]].sum(axis=1)==0\n\nmore_toxic_1 = df_multi[df_multi[[\"severe_toxicity\",\"threat\"]].sum(axis=1)>0.2][\"comment_text\"]\nmore_toxic_2 = df_multi[df_multi[\"toxic\"]>=0.8][\"comment_text\"]\nmore_toxic_3 = df_multi[df_multi[\"identity_attack\"]>=0.8][\"comment_text\"]\nmore_toxic = np.unique(np.concatenate([more_toxic_1, more_toxic_2, more_toxic_3]))\n\nless_toxic_1 = df_multi.loc[((df_multi[\"neutral\"]==1) & (df_multi[\"identity_associated\"]==0)),:].sample(n = 4*len(more_toxic), random_state = CONFIG[\"seed\"])[\"comment_text\"]\nless_toxic_2 = df_multi.loc[((df_multi[\"neutral\"]==1) & (df_multi[\"identity_associated\"]>0)),:].sample(n = len(more_toxic), random_state = CONFIG[\"seed\"])[\"comment_text\"]\n\nless_toxic = np.concatenate([less_toxic_1, less_toxic_2])\nlen(less_toxic), 5*len(more_toxic)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T15:01:43.254546Z","iopub.execute_input":"2022-01-20T15:01:43.255331Z","iopub.status.idle":"2022-01-20T15:01:44.371517Z","shell.execute_reply.started":"2022-01-20T15:01:43.255283Z","shell.execute_reply":"2022-01-20T15:01:44.370514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"more_toxic = more_toxic.repeat(5)\n\nfor l_t, m_t in zip(less_toxic, more_toxic):\n    comment_pairs.append((l_t,m_t))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T15:02:06.161183Z","iopub.execute_input":"2022-01-20T15:02:06.161502Z","iopub.status.idle":"2022-01-20T15:02:06.82342Z","shell.execute_reply.started":"2022-01-20T15:02:06.161454Z","shell.execute_reply":"2022-01-20T15:02:06.822436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(comment_pairs)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T15:02:10.89134Z","iopub.execute_input":"2022-01-20T15:02:10.891655Z","iopub.status.idle":"2022-01-20T15:02:10.897731Z","shell.execute_reply.started":"2022-01-20T15:02:10.891619Z","shell.execute_reply":"2022-01-20T15:02:10.896898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Combining all Together","metadata":{}},{"cell_type":"code","source":"df_2  = pd.DataFrame(comment_pairs, columns = [\"less_toxic\",\"more_toxic\"])\ncombined_data = pd.concat([df[[\"less_toxic\",\"more_toxic\"]], df_2])\ncombined_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T15:02:39.78382Z","iopub.execute_input":"2022-01-20T15:02:39.784158Z","iopub.status.idle":"2022-01-20T15:02:40.080699Z","shell.execute_reply.started":"2022-01-20T15:02:39.784128Z","shell.execute_reply":"2022-01-20T15:02:40.080065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_data[\"less_toxic\"].str.len().describe() ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T15:02:53.727442Z","iopub.execute_input":"2022-01-20T15:02:53.728202Z","iopub.status.idle":"2022-01-20T15:02:54.176821Z","shell.execute_reply.started":"2022-01-20T15:02:53.728164Z","shell.execute_reply":"2022-01-20T15:02:54.17586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = combined_data.sample(frac=1).reset_index(drop=True)\ndf[\"target\"]=1","metadata":{"execution":{"iopub.status.busy":"2022-01-20T15:03:09.405711Z","iopub.execute_input":"2022-01-20T15:03:09.406409Z","iopub.status.idle":"2022-01-20T15:03:09.570917Z","shell.execute_reply.started":"2022-01-20T15:03:09.406358Z","shell.execute_reply":"2022-01-20T15:03:09.5699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef clean(data, col):\n    \n    \n    data[col] = data[col].str.lower()\n    data[col] = data[col].str.replace(r\"what's\", \"what is \")\n    data[col] = data[col].str.replace(r\"\\'s\", \" \")\n    data[col] = data[col].str.replace(r\"\\'ve\", \" have \")\n    data[col] = data[col].str.replace(r\"can't\", \"cannot \")\n    data[col] = data[col].str.replace(r\"n't\", \" not \")\n    data[col] = data[col].str.replace(r\"i'm\", \"i am \")\n    data[col] = data[col].str.replace(r\"\\'re\", \" are \")\n    data[col] = data[col].str.replace(r\"\\'d\", \" would \")\n    data[col] = data[col].str.replace(r\"\\'ll\", \" will \")\n    data[col] = data[col].str.replace(r\"\\'scuse\", \" excuse \")\n    data[col] = data[col].str.replace('\\s+', ' ')\n    \n  \n\n    # Clean some punctutations\n    data[col] = data[col].str.replace('\\n', ' \\n ')\n    # Remove ip address\n    data[col] = data[col].str.replace(r'(([0-9]+\\.){2,}[0-9]+)',' ')\n    \n    # Remove website\n    data[col] = data[col].str.replace(r'https?://\\S+|www\\.\\S+', ' ')\n    \n    \n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')\n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\'\"]+)',r' \\1 ')    \n    # Remove multiple white spaces\n    data[col] = data[col].str.replace(r' +', ' ')\n    # Remove html tags\n    data[col] = data[col].str.replace(r'<[^<]+?>', ' ')\n    \n    return data\n                     \n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T15:59:54.885171Z","iopub.execute_input":"2022-01-20T15:59:54.886077Z","iopub.status.idle":"2022-01-20T15:59:54.903364Z","shell.execute_reply.started":"2022-01-20T15:59:54.886034Z","shell.execute_reply":"2022-01-20T15:59:54.902172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = clean(df, \"less_toxic\")\ndf = clean(df, \"more_toxic\")","metadata":{"execution":{"iopub.status.busy":"2022-01-20T15:59:56.841438Z","iopub.execute_input":"2022-01-20T15:59:56.84223Z","iopub.status.idle":"2022-01-20T16:03:15.207444Z","shell.execute_reply.started":"2022-01-20T15:59:56.84219Z","shell.execute_reply":"2022-01-20T16:03:15.206315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fold prep and training","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:34:21.274047Z","iopub.execute_input":"2021-12-26T05:34:21.275016Z","iopub.status.idle":"2021-12-26T05:34:21.279015Z","shell.execute_reply.started":"2021-12-26T05:34:21.274963Z","shell.execute_reply":"2021-12-26T05:34:21.278227Z"}}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits = CONFIG[\"n_fold\"], shuffle = True, random_state = CONFIG[\"seed\"])\n\nfor fold, (_, val_ind)  in enumerate(skf.split(X = df,y = df[\"target\"])):\n    df.loc[val_ind,\"val_set\"] = int(fold)\n    \ndf[\"val_set\"] = df[\"val_set\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:03:15.209915Z","iopub.execute_input":"2022-01-20T16:03:15.210347Z","iopub.status.idle":"2022-01-20T16:03:15.316117Z","shell.execute_reply.started":"2022-01-20T16:03:15.210301Z","shell.execute_reply":"2022-01-20T16:03:15.315109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawDataset():\n    def __init__(self, df, tokenizer, max_length ):\n        self.df = df\n        self.more_toxic = df[\"more_toxic\"].values\n        self.less_toxic = df[\"less_toxic\"].values\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        more_toxic = self.more_toxic[index]\n        less_toxic = self.less_toxic[index]\n        \n        inputs_more_toxic = self.tokenizer(text = more_toxic , truncation=True, padding= \"max_length\", add_special_tokens = True, max_length = self.max_length)\n        inputs_less_toxic = self.tokenizer(text = less_toxic , truncation=True, padding= \"max_length\", add_special_tokens = True, max_length = self.max_length)\n        \n        more_toxic_ids = inputs_more_toxic[\"input_ids\"]\n        more_toxic_mask = inputs_more_toxic[\"attention_mask\"]\n        \n        less_toxic_ids = inputs_less_toxic[\"input_ids\"]\n        less_toxic_mask = inputs_less_toxic[\"attention_mask\"]\n        \n        target = 1\n        return {\"less_toxic_ids\": torch.tensor(less_toxic_ids),\n               \"less_toxic_mask\": torch.tensor(less_toxic_mask),\n               \"more_toxic_ids\": torch.tensor(more_toxic_ids),\n               \"more_toxic_mask\": torch.tensor(more_toxic_mask),\n                \"target\": torch.tensor(target)}\n                                               \n                                               \n    \n        \n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:03:15.319713Z","iopub.execute_input":"2022-01-20T16:03:15.319987Z","iopub.status.idle":"2022-01-20T16:03:15.331424Z","shell.execute_reply.started":"2022-01-20T16:03:15.319956Z","shell.execute_reply":"2022-01-20T16:03:15.330415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(768, CONFIG[\"num_classes\"])\n        \n    def forward(self, ids, mask):\n        out = self.model(input_ids = ids, attention_mask = mask, output_hidden_states = False)\n        out = self.dropout(out[1])\n        outputs  = self.fc(out)\n        return outputs\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:03:15.333475Z","iopub.execute_input":"2022-01-20T16:03:15.333789Z","iopub.status.idle":"2022-01-20T16:03:15.344145Z","shell.execute_reply.started":"2022-01-20T16:03:15.333757Z","shell.execute_reply":"2022-01-20T16:03:15.343301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Loss Function\n\ndef criterion(outputs1, outputs2, targets):\n    return nn.MarginRankingLoss(margin = CONFIG[\"margin\"])(outputs1, outputs2, targets)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:03:15.345754Z","iopub.execute_input":"2022-01-20T16:03:15.346005Z","iopub.status.idle":"2022-01-20T16:03:15.3607Z","shell.execute_reply.started":"2022-01-20T16:03:15.345978Z","shell.execute_reply":"2022-01-20T16:03:15.35984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, dataloader, scheduler, device, epoch):\n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    for step , data in bar:\n        less_toxic_ids = data[\"less_toxic_ids\"].to(device)\n        less_toxic_mask = data[\"less_toxic_mask\"].to(device)\n        more_toxic_ids = data[\"more_toxic_ids\"].to(device)\n        more_toxic_mask= data[\"more_toxic_mask\"].to(device)\n        targets = data[\"target\"].to(device)\n        batch_size = less_toxic_ids.size(0)\n        \n        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n        \n        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n        loss.backward()\n        \n        optimizer.step()\n        optimizer.zero_grad()\n        if scheduler:\n            scheduler.step()\n            \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:05:02.958098Z","iopub.execute_input":"2022-01-20T16:05:02.959026Z","iopub.status.idle":"2022-01-20T16:05:03.049062Z","shell.execute_reply.started":"2022-01-20T16:05:02.958969Z","shell.execute_reply":"2022-01-20T16:05:03.048329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    dataset_size = 0\n    running_loss = 0.0\n    bar = tqdm(enumerate(dataloader), total = len(dataloader))\n    for step, data in bar:\n        with torch.no_grad():\n            less_toxic_ids = data[\"less_toxic_ids\"].to(device)\n            less_toxic_mask = data[\"less_toxic_mask\"].to(device)\n            more_toxic_ids = data[\"more_toxic_ids\"].to(device)\n            more_toxic_mask= data[\"more_toxic_mask\"].to(device)\n            targets = data[\"target\"].to(device)\n            \n            batch_size = less_toxic_ids.size(0)\n            \n            less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n            more_toxic_outputs = model(more_toxic_ids, more_toxic_mask) \n            \n            loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n            \n            running_loss += (loss.item() * batch_size)\n            dataset_size += batch_size\n        \n            epoch_loss = running_loss / dataset_size\n        \n            bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss\n        \n            \n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:05:06.68268Z","iopub.execute_input":"2022-01-20T16:05:06.683737Z","iopub.status.idle":"2022-01-20T16:05:06.695117Z","shell.execute_reply.started":"2022-01-20T16:05:06.68367Z","shell.execute_reply":"2022-01-20T16:05:06.694207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, num_epochs, device, folds, train_loader, val_loader):\n    \n    wandb.watch(model, log_freq=10)\n    \n    if torch.cuda.is_available():\n        print(\"Using GPU :) ==> {}\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_weights = copy.deepcopy(model.state_dict())\n    best_epoch_loss= np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs+1):\n        gc.collect()\n        \n        train_epoch_loss =  train_one_epoch(model, optimizer, dataloader = train_loader, scheduler = scheduler, device = CONFIG[\"device\"], epoch= epoch)\n        \n        val_epoch_loss = valid_one_epoch(model,dataloader = val_loader,device = CONFIG[\"device\"], epoch=epoch)\n        \n        history[\"train_loss\"].append(train_epoch_loss)\n        history[\"val_loss\"].append(val_epoch_loss)\n        \n        wandb.log({\"Train Loss\": train_epoch_loss})\n        wandb.log({\"Valid Loss\": val_epoch_loss})\n        \n        if val_epoch_loss <= best_epoch_loss:\n            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n            best_epoch_loss = val_epoch_loss\n            run.summary[\"Best Loss\"] = best_epoch_loss\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = f\"Loss-Fold-{fold}.bin\"\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n        \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:05:13.168474Z","iopub.execute_input":"2022-01-20T16:05:13.168777Z","iopub.status.idle":"2022-01-20T16:05:13.183395Z","shell.execute_reply.started":"2022-01-20T16:05:13.168747Z","shell.execute_reply":"2022-01-20T16:05:13.182479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(fold):\n    df_train = df[df[\"val_set\"]!= fold]\n    df_val = df[df[\"val_set\"]==fold]\n    \n    train_dataset = JigsawDataset(df_train, CONFIG[\"tokenizer\"], CONFIG[\"max_length\"])\n    \n    val_dataset = JigsawDataset(df_val, CONFIG[\"tokenizer\"], CONFIG[\"max_length\"])\n    \n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n    \n    val_loader = DataLoader(val_dataset, batch_size=CONFIG['val_batch_size'], \n                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n    \n    return train_loader, val_loader\n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:05:24.105492Z","iopub.execute_input":"2022-01-20T16:05:24.105802Z","iopub.status.idle":"2022-01-20T16:05:24.113428Z","shell.execute_reply.started":"2022-01-20T16:05:24.105764Z","shell.execute_reply":"2022-01-20T16:05:24.112553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'cosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'cosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n                                                             eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:05:27.945217Z","iopub.execute_input":"2022-01-20T16:05:27.946011Z","iopub.status.idle":"2022-01-20T16:05:27.953478Z","shell.execute_reply.started":"2022-01-20T16:05:27.945961Z","shell.execute_reply":"2022-01-20T16:05:27.952869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(0, CONFIG['n_fold']):\n    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n    run = wandb.init(project='Jigsaw', \n                     config=CONFIG,\n                     job_type='Train',\n                     group=CONFIG['group'],\n                     tags=['roberta-base', f'{HASH_NAME}', 'margin-loss'],\n                     name=f'{HASH_NAME}-fold-{fold}',\n                     anonymous='must')\n    \n    # Create Dataloaders\n    train_loader, valid_loader = prepare_loaders(fold=fold)\n    \n    model = JigsawModel(CONFIG['model_name'])\n    model.to(CONFIG['device'])\n    \n    # Define Optimizer and Scheduler\n    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n    scheduler = fetch_scheduler(optimizer)\n                        \n    model, history = run_training(model, optimizer, scheduler,\n                                  device=CONFIG['device'],\n                                  num_epochs=CONFIG['num_epochs'],\n                                  folds=fold,\n                                  train_loader  = train_loader, val_loader = valid_loader)\n    \n    run.finish()\n    \n    del model, history, train_loader, valid_loader\n    _ = gc.collect()\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:05:39.009459Z","iopub.execute_input":"2022-01-20T16:05:39.010049Z","iopub.status.idle":"2022-01-20T16:06:17.91567Z","shell.execute_reply.started":"2022-01-20T16:05:39.009995Z","shell.execute_reply":"2022-01-20T16:06:17.913917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:55:00.381385Z","iopub.status.idle":"2021-12-26T05:55:00.38198Z","shell.execute_reply.started":"2021-12-26T05:55:00.381714Z","shell.execute_reply":"2021-12-26T05:55:00.381764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}